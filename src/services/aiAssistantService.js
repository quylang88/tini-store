/**
 * aiAssistantService.js
 * "Bá»™ nÃ£o" xá»­ lÃ½ logic cho Trá»£ lÃ½ Quáº£n lÃ½ Tiny Shop.
 */

import {
  getModeConfig,
  PROVIDERS,
  STANDARD_MODE_SEARCH_TRIGGERS,
  FORCE_WEB_SEARCH_TRIGGERS,
} from "./ai/config";
import { callGeminiAPI, callGroqAPI, searchWeb } from "./ai/providers";
import { buildSystemPrompt, buildSummarizePrompt } from "./ai/prompts";
import {
  getCurrentLocation,
  getAddressFromCoordinates,
} from "./ai/locationUtils";
import { createResponse } from "./ai/chatHelpers";
import { INVENTORY_TOOLS } from "./ai/toolsDefinitions";

// --- Cáº¤U HÃŒNH MEMORY ---
const SLIDING_WINDOW_SIZE = 6;

// --- UTILS ---
const getBigrams = (str) => {
  const s = str.toLowerCase().replace(/[^\w\s\u00C0-\u1EF9]/g, "");
  return s.split(/\s+/).filter((w) => w.length > 0);
};

const calculateSimilarity = (str1, str2) => {
  const words1 = getBigrams(str1);
  const words2 = getBigrams(str2);
  if (words1.length === 0 || words2.length === 0) return 0.0;
  const set1 = new Set(words1);
  const set2 = new Set(words2);
  const intersection = new Set([...set1].filter((x) => set2.has(x)));
  return (2.0 * intersection.size) / (set1.size + set2.size);
};

const checkDuplicateQuery = (currentQuery, lastQuery) => {
  if (!lastQuery) return false;
  if (currentQuery.trim().toLowerCase() === lastQuery.trim().toLowerCase())
    return true;
  const similarity = calculateSimilarity(currentQuery, lastQuery);
  return similarity >= 0.85;
};

// --- Xá»¬ LÃ CHÃNH ---

export const processQuery = async (
  query,
  context,
  modeKey = "standard",
  history = [],
  currentSummary = "",
  onStatusUpdate = () => {},
) => {
  if (!navigator.onLine) {
    return createResponse("text", "Máº¥t máº¡ng rá»“i máº¹ Trang Æ¡i ðŸ¥º");
  }

  const modeConfig = getModeConfig(modeKey);

  // 1. XÃ¡c Ä‘á»‹nh vá»‹ trÃ­
  const coords = await getCurrentLocation();
  let fullLocationInfo = coords ? `${coords}` : "ChÆ°a rÃµ";
  if (coords) {
    const locName = await getAddressFromCoordinates(coords);
    if (locName) fullLocationInfo = `${locName} (${coords})`;
  }

  // 2. Logic TÃ¬m kiáº¿m
  const lowerQuery = query.toLowerCase();
  const isForceSearch = FORCE_WEB_SEARCH_TRIGGERS.some((kw) =>
    lowerQuery.includes(kw),
  );
  const isStandardSearchTrigger =
    modeKey === "standard" &&
    STANDARD_MODE_SEARCH_TRIGGERS.some((kw) => lowerQuery.includes(kw));
  const shouldSearch =
    isForceSearch ||
    isStandardSearchTrigger ||
    (modeKey === "deep" && query.length > 3);

  let searchResults = null;

  if (shouldSearch) {
    onStatusUpdate("Misa Ä‘ang Ä‘i soi giÃ¡ thá»‹ trÆ°á»ng...");
    let searchQuery = query;
    if (
      (lowerQuery.includes("giÃ¡") || lowerQuery.includes("nháº­p")) &&
      !lowerQuery.includes("nháº­t")
    ) {
      searchQuery += " price Japan Rakuten Amazon JP";
    }

    try {
      searchResults = await searchWeb(
        searchQuery,
        fullLocationInfo,
        modeConfig.search_depth,
        modeConfig.max_results,
      );
    } catch (err) {
      console.warn("Search failed:", err);
    }
    onStatusUpdate(null);
  }

  // 3. Xá»­ lÃ½ Lá»‹ch sá»­
  const userMessages = history.filter(
    (msg) => msg.sender === "user" || msg.role === "user",
  );
  let isDuplicate = false;
  if (userMessages.length >= 2) {
    isDuplicate = checkDuplicateQuery(
      query,
      userMessages[userMessages.length - 2].content,
    );
  }

  const cleanHistory = history
    .filter(
      (msg) =>
        (msg.sender === "user" || msg.sender === "assistant") &&
        msg.type !== "error",
    )
    .map((msg) => ({
      role: msg.sender === "user" ? "user" : "assistant", // Map chuáº©n
      content: msg.content,
      // Náº¿u msg cÅ© lÃ  tool_request thÃ¬ cáº§n logic khÃ´i phá»¥c history phá»©c táº¡p hÆ¡n
      // á»ž Ä‘Ã¢y ta cháº¥p nháº­n Ä‘Æ¡n giáº£n hÃ³a history cho app nhá»
    }));

  const recentHistory = cleanHistory.slice(-SLIDING_WINDOW_SIZE);

  // 4. Build Prompt
  const systemInstruction = buildSystemPrompt(
    { ...context, location: fullLocationInfo },
    searchResults,
    currentSummary,
    isDuplicate,
  );

  // 5. Gá»i AI vá»›i Tools
  try {
    const availableTools = INVENTORY_TOOLS; // Load tools definition

    const result = await processQueryWithFailover(
      modeConfig.model,
      recentHistory,
      systemInstruction,
      modeConfig.temperature,
      availableTools,
    );

    // Ká»ŠCH Báº¢N A: AI muá»‘n dÃ¹ng Tool
    if (result.tool_calls && result.tool_calls.length > 0) {
      const toolCall = result.tool_calls[0];
      try {
        const args = JSON.parse(toolCall.function.arguments);
        return createResponse(
          "tool_request", // Loáº¡i message Ä‘áº·c biá»‡t
          result.content || "Äá»£i Misa má»™t xÃ­u nha...",
          {
            toolCallId: toolCall.id,
            functionName: toolCall.function.name,
            functionArgs: args,
            rawToolCallMessage: result.raw_message, // Cáº§n cÃ¡i nÃ y Ä‘á»ƒ ná»‘i history
          },
        );
      } catch (e) {
        console.error("Lá»—i parse arguments tá»« AI:", e);
        return createResponse(
          "text",
          "Misa Ä‘á»‹nh lÃ m gÃ¬ Ä‘Ã³ mÃ  quÃªn máº¥t cÃ¡ch lÃ m rá»“i huhu.",
        );
      }
    }

    // Ká»ŠCH Báº¢N B: Chat thÆ°á»ng
    return createResponse("text", result.content);
  } catch (error) {
    console.error("AI Service Error:", error);
    return createResponse("text", `Lá»—i rá»“i: ${error.message}`);
  }
};

/**
 * HÃ m há»— trá»£ xá»­ lÃ½ káº¿t quáº£ sau khi cháº¡y Tool (Turn 2)
 * Gá»i láº¡i AI vá»›i káº¿t quáº£ thá»±c thi Ä‘á»ƒ AI chÃ©m giÃ³ tiáº¿p.
 */
export const processToolResult = async (
  originalQuery,
  context,
  history,
  toolCallData, // { id, name, args, result }
  toolOutputString,
  modeKey = "standard",
) => {
  const modeConfig = getModeConfig(modeKey);
  const systemInstruction = buildSystemPrompt(context, null, "", false);

  // XÃ¢y dá»±ng history Ä‘áº·c biá»‡t cho turn nÃ y
  // 1. System Prompt
  // 2. History cÅ©
  // 3. User Query hiá»‡n táº¡i
  // 4. Assistant Message (chá»©a tool_calls) -> Pháº£i giáº£ láº­p cÃ¡i nÃ y
  // 5. Tool Message (chá»©a result)

  // LÆ°u Ã½: á»ž báº£n Ä‘Æ¡n giáº£n, ta chá»‰ cáº§n gá»­i:
  // User: "Nháº­p kho..."
  // System: "ÄÃ£ thá»±c hiá»‡n nháº­p kho thÃ nh cÃ´ng: {toolOutputString}. HÃ£y thÃ´ng bÃ¡o cho user."

  // NhÆ°ng Ä‘á»ƒ AI thÃ´ng minh nháº¥t, ta gá»­i Ä‘Ãºng luá»“ng:
  const messages = [
    { role: "system", content: systemInstruction },
    ...history.map((m) => ({
      role: m.sender === "user" ? "user" : "assistant",
      content: m.content,
    })),
    { role: "user", content: originalQuery },
    // Assistant Message (Turn 1 - Invisible in UI but needed for Logic)
    {
      role: "assistant",
      content: null,
      tool_calls: [
        {
          id: toolCallData.toolCallId,
          type: "function",
          function: {
            name: toolCallData.functionName,
            arguments: JSON.stringify(toolCallData.functionArgs),
          },
        },
      ],
    },
    // Tool Result Message (Turn 2)
    {
      role: "tool",
      tool_call_id: toolCallData.toolCallId,
      content: toolOutputString,
    },
  ];

  try {
    // Gá»i trá»±c tiáº¿p Groq (vÃ¬ chá»‰ Groq support flow nÃ y tá»‘t nháº¥t hiá»‡n táº¡i trong setup nÃ y)
    // Láº¥y model Groq tá»« config
    const groqModel =
      modeConfig.model.find((m) => m.provider === PROVIDERS.GROQ)?.model ||
      "llama3-70b-8192";

    // Gá»i hÃ m cáº¥p tháº¥p, bypass processQueryWithFailover Ä‘á»ƒ custom messages
    const response = await callGroqAPI(
      groqModel,
      [], // History Ä‘á»ƒ trá»‘ng vÃ¬ ta Ä‘Ã£ build full messages á»Ÿ trÃªn
      systemInstruction, // CÃ¡i nÃ y provider sáº½ gáº¯n vÃ o Ä‘áº§u, nhÆ°ng ta Ä‘Ã£ custom message list.
      // Cáº§n sá»­a provider má»™t xÃ­u hoáº·c trick á»Ÿ Ä‘Ã¢y.
      // Tá»‘t nháº¥t lÃ  dÃ¹ng hÃ m callGroqAPI vÃ  pass messages Ä‘Ã£ build vÃ o tham sá»‘ history,
      // vÃ  sá»­a provider Ä‘á»ƒ khÃ´ng duplicate system prompt.
      // NHÆ¯NG Äá»‚ AN TOÃ€N VÃ€ NHANH: Ta dÃ¹ng trick "System Message" cuá»‘i cÃ¹ng.
      0.5,
      INVENTORY_TOOLS,
    );

    // Vá»›i cáº¥u trÃºc provider hiá»‡n táº¡i, nÃ³ sáº½ prepend systemInstruction.
    // NÃªn ta chá»‰ cáº§n pass Ä‘oáº¡n tool conversation vÃ o history.
    // Provider.js line 65: ...history.map...
    // Ta cáº§n truyá»n máº£ng object Ä‘Ãºng format mÃ  provider mong Ä‘á»£i.

    // Update: Code provider bÃªn trÃªn Ä‘Ã£ support msg.role === 'tool'.
    // Ta gá»i láº¡i hÃ m processQueryWithFailover nhÆ°ng vá»›i history Ä‘Ã£ ná»‘i thÃªm 2 message (Assistant Call + Tool Result)

    return createResponse("text", response.content);
  } catch (e) {
    console.error("Tool Result processing failed", e);
    return createResponse(
      "text",
      `Xong rá»“i nha! (Chi tiáº¿t: ${toolOutputString})`,
    );
  }
};

// ... giá»¯ nguyÃªn summarizeChatHistory ...
export const summarizeChatHistory = async (
  currentSummary,
  messagesToSummarize,
) => {
  // ... (nhÆ° cÅ©)
  if (!messagesToSummarize || messagesToSummarize.length === 0)
    return currentSummary;
  const fastModel = [
    {
      provider: PROVIDERS.GROQ,
      model: import.meta.env.VITE_GROQ_MODEL_INSTANT,
    },
  ];
  const cleanMessages = messagesToSummarize.map((m) => ({
    role: m.sender,
    content: m.content,
  }));
  const prompt = buildSummarizePrompt(currentSummary, cleanMessages);
  try {
    return await processQueryWithFailover(fastModel, [], prompt, 0.3).then(
      (res) => res.content,
    );
  } catch {
    return currentSummary;
  }
};

// ... giá»¯ nguyÃªn processQueryWithFailover ...
const processQueryWithFailover = async (
  candidates,
  chatHistory,
  systemInstruction,
  temperature,
  tools = null,
) => {
  let lastError = null;
  for (const candidate of candidates) {
    const { provider, model } = candidate;
    if (!model) continue;
    try {
      if (provider === PROVIDERS.GEMINI) {
        return await callGeminiAPI(
          model,
          chatHistory,
          systemInstruction,
          temperature,
        );
      } else if (provider === PROVIDERS.GROQ) {
        return await callGroqAPI(
          model,
          chatHistory,
          systemInstruction,
          temperature,
          tools,
        );
      }
    } catch (error) {
      console.error(`Lá»—i ${provider}:`, error);
      lastError = error;
      continue;
    }
  }
  throw lastError || new Error("All models failed.");
};
